# AI Chat Website

Welcome to the **AI Chat Website** repository! This project is a lightweight, conversational AI web application that utilizes the Ollama API to provide engaging and intuitive chatbot functionality.

## ğŸš€ Features
- **Interactive Chat Interface**: Communicate with an AI model through a user-friendly chat interface.
- **AI-Powered Conversations**: Leverages the Ollama API to process and generate responses.
- **Real-Time Responses**: Quick and seamless interactions for an enjoyable user experience.
- **Modular Codebase**: Clean and scalable structure for easy customization and updates.

## ğŸ“‹ Prerequisites
Before running the project, ensure you have the following installed:
- **Node.js** (v22 or higher)
- **npm** or **yarn**
- Ollama CLI (for pulling the AI model)

## ğŸ“‚ Folder Structure
```
ğŸ“¦ root
â”œâ”€â”€ ğŸ“ public              # Static assets for the front-end
â”œâ”€â”€ ğŸ“ src                 # Source code for the web app
â”‚   â”œâ”€â”€ ğŸ“„ index.js        # Main server file
â”‚   â”œâ”€â”€ ğŸ“„ Message.tsx     # Chat message component
â”‚   â””â”€â”€ ğŸ“„ App.js          # Main application logic
â”œâ”€â”€ ğŸ“„ package.json        # Project dependencies and scripts
â””â”€â”€ ğŸ“„ README.md           # Project documentation
```

## ğŸ› ï¸ Setup & Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/YourUsername/ai-chat-website.git
   cd ai-chat-website
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Pull the required AI model:
   ```bash
   npx ollama pull llama3.2
   ```

4. Start the development server:
   ```bash
   npm start
   ```

## âš™ï¸ Configuration
- Ensure the **Ollama API** is correctly configured in your environment.
- Set up environment variables (if applicable) in a `.env` file:
  ```
  API_KEY=your_api_key
  MODEL_NAME=llama3.2
  ```

## ğŸŒ Deployment
### Local Deployment
Run the server locally:
```bash
node index.js
```

### Cloud Deployment
1. Use a platform like Render or Vercel.
2. Ensure `npm install` and `npx ollama pull llama3.2` are executed during the build phase.
3. Set up your deployment commands to start the app (`npm start`).

## ğŸ¤ Contributing
1. Fork this repository.
2. Create a feature branch: `git checkout -b feature-name`.
3. Commit your changes: `git commit -m "Add some feature"`.
4. Push to the branch: `git push origin feature-name`.
5. Open a pull request.

## ğŸ› Known Issues
- `ollama pull` may fail during deployment due to missing dependencies or path errors. Ensure the Ollama CLI is installed globally or adjust the `postinstall` script.

## ğŸ“œ License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

Happy coding! ğŸ˜Š If you encounter any issues, feel free to open an [issue](https://github.com/YourUsername/ai-chat-website/issues).
